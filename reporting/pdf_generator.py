"""
Generador de reportes PDF profesionales para pruebas de integraci√≥n AgroWeb
Crea documentos formales con logos universitarios, gr√°ficos y an√°lisis completo
"""

import os
import json
from datetime import datetime
from typing import Dict, Any, List, Tuple
import logging

# PDF Generation
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib.colors import Color, black, white, darkblue, lightgrey, green, red, orange
from reportlab.lib import colors
from reportlab.graphics.shapes import Drawing
from reportlab.graphics.charts.linecharts import HorizontalLineChart
from reportlab.graphics.charts.barcharts import VerticalBarChart
from reportlab.graphics.charts.piecharts import Pie

# Data Analysis and Visualization
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from io import BytesIO
import base64

# Configuration
from config.productos.test_config import TestConfig

logger = logging.getLogger(__name__)

class PDFReportGenerator:
    """Generador de reportes PDF profesionales para resultados de testing"""
    
    def __init__(self):
        self.styles = getSampleStyleSheet()
        self.custom_styles = self._create_custom_styles()
        self.colors = {
            'primary': Color(0.2, 0.3, 0.7),  # Azul institucional
            'success': Color(0.2, 0.7, 0.3),  # Verde
            'warning': Color(0.9, 0.7, 0.1),  # Amarillo
            'error': Color(0.8, 0.2, 0.2),    # Rojo
            'light_blue': Color(0.9, 0.95, 1.0),  # Azul claro
            'light_gray': Color(0.95, 0.95, 0.95)  # Gris claro
        }
    
    def _create_custom_styles(self):
        """Crear estilos personalizados para el documento"""
        custom = {}
        
        # T√≠tulo principal
        custom['title'] = ParagraphStyle(
            'CustomTitle',
            parent=self.styles['Heading1'],
            fontSize=24,
            spaceAfter=30,
            alignment=1,  # Centrado
            textColor=colors.darkblue,
            fontName='Helvetica-Bold'
        )
        
        # Subt√≠tulos
        custom['subtitle'] = ParagraphStyle(
            'CustomSubtitle',
            parent=self.styles['Heading2'],
            fontSize=16,
            spaceAfter=20,
            textColor=colors.darkblue,
            fontName='Helvetica-Bold'
        )
        
        # Texto del header universitario
        custom['university'] = ParagraphStyle(
            'University',
            parent=self.styles['Normal'],
            fontSize=12,
            alignment=1,
            textColor=colors.darkblue,
            fontName='Helvetica-Bold'
        )
        
        # Texto normal mejorado
        custom['body'] = ParagraphStyle(
            'CustomBody',
            parent=self.styles['Normal'],
            fontSize=10,
            spaceAfter=12,
            fontName='Helvetica'
        )
        
        # Texto para m√©tricas
        custom['metric'] = ParagraphStyle(
            'Metric',
            parent=self.styles['Normal'],
            fontSize=11,
            fontName='Helvetica-Bold',
            textColor=colors.darkblue
        )
        
        return custom
    
    def generate_integration_report(self, output_dir: str = None) -> str:
        """Generar reporte PDF completo de pruebas de integraci√≥n"""
        
        # Configurar directorio de salida
        if not output_dir:
            output_dir = TestConfig.ensure_report_directory()
        
        timestamp = TestConfig.get_report_timestamp()
        filename = f"AgroWeb_Integration_Report_{timestamp}.pdf"
        filepath = os.path.join(output_dir, filename)
        
        logger.info(f"üìÑ Generando reporte PDF: {filepath}")
        
        # Cargar datos de pruebas
        test_data = self._load_test_results()
        
        # Crear documento PDF
        doc = SimpleDocTemplate(
            filepath,
            pagesize=A4,
            rightMargin=72,
            leftMargin=72,
            topMargin=72,
            bottomMargin=18
        )
        
        # Construir contenido
        story = []
        
        # P√°gina de portada
        story.extend(self._create_cover_page())
        story.append(PageBreak())
        
        # Resumen ejecutivo
        story.extend(self._create_executive_summary(test_data))
        story.append(PageBreak())
        
        # Resultados detallados
        story.extend(self._create_detailed_results(test_data))
        story.append(PageBreak())
        
        # An√°lisis de rendimiento
        story.extend(self._create_performance_analysis(test_data))
        story.append(PageBreak())
        
        # An√°lisis de errores
        story.extend(self._create_error_analysis(test_data))
        story.append(PageBreak())
        
        # Recomendaciones
        story.extend(self._create_recommendations(test_data))
        
        # Construir PDF
        doc.build(story)
        
        logger.info(f"‚úÖ Reporte PDF generado exitosamente: {filepath}")
        return filepath
    
    def _load_test_results(self) -> Dict[str, Any]:
        """Cargar resultados de pruebas desde archivos JSON"""
        
        try:
            # Buscar archivo de resultados m√°s reciente
            reports_dir = "reports"
            json_files = [f for f in os.listdir(reports_dir) if f.endswith('.json')]
            
            if not json_files:
                logger.warning("No se encontraron archivos de resultados JSON")
                return self._generate_sample_data()
            
            # Usar el archivo m√°s reciente
            latest_file = max(json_files, key=lambda x: os.path.getctime(os.path.join(reports_dir, x)))
            
            with open(os.path.join(reports_dir, latest_file), 'r', encoding='utf-8') as f:
                data = json.load(f)
                logger.info(f"üìä Datos cargados desde: {latest_file}")
                return data
                
        except Exception as e:
            logger.warning(f"Error cargando resultados: {e}. Usando datos de ejemplo.")
            return self._generate_sample_data()
    
    def _generate_sample_data(self) -> Dict[str, Any]:
        """Generar datos de ejemplo para el reporte"""
        return {
            "summary": {
                "total_tests": 25,
                "passed": 23,
                "failed": 2,
                "skipped": 0,
                "duration": 45.6,
                "success_rate": 92.0
            },
            "tests": [
                {
                    "name": "test_health_check",
                    "outcome": "passed",
                    "duration": 0.15,
                    "categories": ["api", "smoke"]
                },
                {
                    "name": "test_create_product",
                    "outcome": "passed", 
                    "duration": 0.32,
                    "categories": ["api", "integration"]
                },
                {
                    "name": "test_invalid_data",
                    "outcome": "failed",
                    "duration": 0.28,
                    "categories": ["error_handling"]
                }
            ],
            "performance": {
                "response_times": {
                    "health_check": [120, 115, 125, 110, 118],
                    "get_products": [180, 175, 190, 170, 185],
                    "create_product": [250, 240, 260, 245, 255]
                },
                "thresholds": {
                    "health_check": 100,
                    "get_products": 200,
                    "create_product": 300
                }
            },
            "errors": {
                "400": 5,
                "404": 3,
                "415": 1,
                "500": 0
            }
        }
    
    def _create_cover_page(self) -> List:
        """Crear p√°gina de portada con informaci√≥n universitaria"""
        elements = []
        
        # Logo universitario (si existe)
        logo_path = TestConfig.UNIVERSITY_INFO["logo_path"]
        if os.path.exists(logo_path):
            try:
                logo = Image(logo_path, width=2*inch, height=2*inch)
                logo.hAlign = 'CENTER'
                elements.append(logo)
                elements.append(Spacer(1, 0.5*inch))
            except:
                logger.warning("No se pudo cargar el logo universitario")
        
        # Informaci√≥n universitaria
        university_info = [
            TestConfig.UNIVERSITY_INFO["name"],
            TestConfig.UNIVERSITY_INFO["faculty"],
            TestConfig.UNIVERSITY_INFO["department"],
            TestConfig.UNIVERSITY_INFO["course"],
            f"Semestre {TestConfig.UNIVERSITY_INFO['semester']}"
        ]
        
        for info in university_info:
            p = Paragraph(info, self.custom_styles['university'])
            elements.append(p)
        
        elements.append(Spacer(1, 1*inch))
        
        # T√≠tulo del proyecto
        title = Paragraph(
            TestConfig.UNIVERSITY_INFO["project"],
            self.custom_styles['title']
        )
        elements.append(title)
        
        # Subt√≠tulo del reporte
        subtitle = Paragraph(
            "Reporte de Pruebas de Integraci√≥n",
            self.custom_styles['subtitle']
        )
        elements.append(subtitle)
        
        elements.append(Spacer(1, 1*inch))
        
        # Informaci√≥n del equipo y fecha
        team_info = [
            f"<b>Equipo:</b> {TestConfig.UNIVERSITY_INFO['team']}",
            f"<b>Fecha de Generaci√≥n:</b> {datetime.now().strftime('%d de %B de %Y')}",
            f"<b>Hora:</b> {datetime.now().strftime('%H:%M:%S')}"
        ]
        
        for info in team_info:
            p = Paragraph(info, self.custom_styles['body'])
            elements.append(p)
        
        return elements
    
    def _create_executive_summary(self, test_data: Dict[str, Any]) -> List:
        """Crear resumen ejecutivo con m√©tricas clave"""
        elements = []
        
        # T√≠tulo de secci√≥n
        title = Paragraph("Resumen Ejecutivo", self.custom_styles['subtitle'])
        elements.append(title)
        
        # Introducci√≥n
        intro_text = """
        Este reporte presenta los resultados de las pruebas de integraci√≥n realizadas sobre el 
        microservicio de gesti√≥n de productos de la plataforma AgroWeb. Las pruebas abarcan 
        funcionalidades completas del API REST, casos de error, y an√°lisis de rendimiento.
        """
        intro = Paragraph(intro_text, self.custom_styles['body'])
        elements.append(intro)
        
        elements.append(Spacer(1, 0.3*inch))
        
        # M√©tricas principales
        summary = test_data.get("summary", {})
        
        metrics_data = [
            ["M√©trica", "Valor", "Estado"],
            ["Pruebas Totales", str(summary.get("total_tests", 0)), "‚úì"],
            ["Pruebas Exitosas", str(summary.get("passed", 0)), "‚úì"],
            ["Pruebas Fallidas", str(summary.get("failed", 0)), "‚ö†" if summary.get("failed", 0) > 0 else "‚úì"],
            ["Tasa de √âxito", f"{summary.get('success_rate', 0):.1f}%", "‚úì" if summary.get('success_rate', 0) >= 90 else "‚ö†"],
            ["Duraci√≥n Total", f"{summary.get('duration', 0):.1f} segundos", "‚úì"],
        ]
        
        metrics_table = Table(metrics_data, colWidths=[2.5*inch, 1.5*inch, 1*inch])
        metrics_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), self.colors['primary']),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), self.colors['light_blue']),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        
        elements.append(metrics_table)
        elements.append(Spacer(1, 0.3*inch))
        
        # Conclusi√≥n del resumen
        success_rate = summary.get('success_rate', 0)
        if success_rate >= 95:
            conclusion = "üéØ <b>EXCELENTE:</b> El sistema demuestra alta estabilidad y confiabilidad."
        elif success_rate >= 90:
            conclusion = "‚úÖ <b>BUENO:</b> El sistema funciona correctamente con oportunidades menores de mejora."
        elif success_rate >= 80:
            conclusion = "‚ö†Ô∏è <b>ACEPTABLE:</b> El sistema requiere atenci√≥n en algunas √°reas cr√≠ticas."
        else:
            conclusion = "‚ùå <b>CR√çTICO:</b> El sistema presenta problemas significativos que requieren atenci√≥n inmediata."
        
        conclusion_p = Paragraph(conclusion, self.custom_styles['body'])
        elements.append(conclusion_p)
        
        return elements
    
    def _create_detailed_results(self, test_data: Dict[str, Any]) -> List:
        """Crear secci√≥n de resultados detallados por categor√≠a"""
        elements = []
        
        # T√≠tulo de secci√≥n
        title = Paragraph("Resultados Detallados por Categor√≠a", self.custom_styles['subtitle'])
        elements.append(title)
        
        # Agrupar pruebas por categor√≠a
        tests = test_data.get("tests", [])
        categories = {}
        
        for test in tests:
            test_categories = test.get("categories", ["general"])
            for cat in test_categories:
                if cat not in categories:
                    categories[cat] = []
                categories[cat].append(test)
        
        # Crear tabla para cada categor√≠a
        for category, category_tests in categories.items():
            cat_title = Paragraph(f"Categor√≠a: {TestConfig.TEST_CATEGORIES.get(category, category)}", 
                                 self.custom_styles['body'])
            elements.append(cat_title)
            
            # Calcular estad√≠sticas de la categor√≠a
            passed = len([t for t in category_tests if t.get("outcome") == "passed"])
            total = len(category_tests)
            success_rate = (passed / total * 100) if total > 0 else 0
            
            # Tabla de resultados
            table_data = [["Prueba", "Resultado", "Duraci√≥n (s)", "Estado"]]
            
            for test in category_tests:
                outcome = test.get("outcome", "unknown")
                duration = test.get("duration", 0)
                
                if outcome == "passed":
                    status = "‚úÖ PASS"
                    status_color = self.colors['success']
                elif outcome == "failed":
                    status = "‚ùå FAIL"
                    status_color = self.colors['error']
                else:
                    status = "‚è∏Ô∏è SKIP"
                    status_color = self.colors['warning']
                
                table_data.append([
                    test.get("name", "Unknown"),
                    outcome.upper(),
                    f"{duration:.3f}",
                    status
                ])
            
            results_table = Table(table_data, colWidths=[3*inch, 1*inch, 1*inch, 1*inch])
            results_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), self.colors['primary']),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 9),
                ('BACKGROUND', (0, 1), (-1, -1), self.colors['light_gray']),
                ('GRID', (0, 0), (-1, -1), 1, colors.black),
                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE')
            ]))
            
            elements.append(results_table)
            
            # Estad√≠sticas de la categor√≠a
            stats_text = f"<b>Resumen:</b> {passed}/{total} pruebas exitosas ({success_rate:.1f}%)"
            stats = Paragraph(stats_text, self.custom_styles['body'])
            elements.append(stats)
            elements.append(Spacer(1, 0.2*inch))
        
        return elements
    
    def _create_performance_analysis(self, test_data: Dict[str, Any]) -> List:
        """Crear an√°lisis de rendimiento con gr√°ficos"""
        elements = []
        
        # T√≠tulo de secci√≥n
        title = Paragraph("An√°lisis de Rendimiento", self.custom_styles['subtitle'])
        elements.append(title)
        
        # Texto introductorio
        intro = Paragraph(
            "El an√°lisis de rendimiento eval√∫a los tiempos de respuesta de cada endpoint "
            "contra los umbrales establecidos para garantizar una experiencia de usuario √≥ptima.",
            self.custom_styles['body']
        )
        elements.append(intro)
        elements.append(Spacer(1, 0.2*inch))
        
        # Datos de rendimiento
        performance = test_data.get("performance", {})
        response_times = performance.get("response_times", {})
        thresholds = performance.get("thresholds", {})
        
        if response_times:
            # Crear gr√°fico de rendimiento usando matplotlib
            chart_path = self._create_performance_chart(response_times, thresholds)
            if chart_path and os.path.exists(chart_path):
                try:
                    chart_img = Image(chart_path, width=6*inch, height=4*inch)
                    chart_img.hAlign = 'CENTER'
                    elements.append(chart_img)
                    elements.append(Spacer(1, 0.2*inch))
                except:
                    logger.warning("No se pudo incluir gr√°fico de rendimiento")
            
            # Tabla de m√©tricas de rendimiento
            perf_data = [["Endpoint", "Promedio (ms)", "Umbral (ms)", "Estado"]]
            
            for endpoint, times in response_times.items():
                avg_time = np.mean(times) if times else 0
                threshold = thresholds.get(endpoint, 200)
                
                status = "‚úÖ R√ÅPIDO" if avg_time <= threshold else "‚ö†Ô∏è LENTO"
                
                perf_data.append([
                    endpoint.replace("_", " ").title(),
                    f"{avg_time:.1f}",
                    f"{threshold}",
                    status
                ])
            
            perf_table = Table(perf_data, colWidths=[2*inch, 1.5*inch, 1.5*inch, 1.5*inch])
            perf_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), self.colors['primary']),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 10),
                ('BACKGROUND', (0, 1), (-1, -1), self.colors['light_blue']),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            elements.append(perf_table)
        
        return elements
    
    def _create_performance_chart(self, response_times: Dict, thresholds: Dict) -> str:
        """Crear gr√°fico de rendimiento con matplotlib"""
        try:
            plt.style.use('seaborn-v0_8')
            fig, ax = plt.subplots(figsize=(10, 6))
            
            endpoints = list(response_times.keys())
            avg_times = [np.mean(times) for times in response_times.values()]
            threshold_values = [thresholds.get(endpoint, 200) for endpoint in endpoints]
            
            x = np.arange(len(endpoints))
            width = 0.35
            
            bars1 = ax.bar(x - width/2, avg_times, width, label='Tiempo Promedio', color='skyblue')
            bars2 = ax.bar(x + width/2, threshold_values, width, label='Umbral', color='lightcoral')
            
            ax.set_xlabel('Endpoints')
            ax.set_ylabel('Tiempo de Respuesta (ms)')
            ax.set_title('An√°lisis de Rendimiento por Endpoint')
            ax.set_xticks(x)
            ax.set_xticklabels([e.replace('_', ' ').title() for e in endpoints], rotation=45)
            ax.legend()
            
            # A√±adir valores sobre las barras
            for bar in bars1:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.1f}', ha='center', va='bottom')
            
            plt.tight_layout()
            
            # Guardar gr√°fico
            chart_path = os.path.join("reports", "performance_chart.png")
            plt.savefig(chart_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            return chart_path
            
        except Exception as e:
            logger.error(f"Error creando gr√°fico de rendimiento: {e}")
            return None
    
    def _create_error_analysis(self, test_data: Dict[str, Any]) -> List:
        """Crear an√°lisis de manejo de errores"""
        elements = []
        
        # T√≠tulo de secci√≥n
        title = Paragraph("An√°lisis de Manejo de Errores", self.custom_styles['subtitle'])
        elements.append(title)
        
        # Descripci√≥n
        desc = Paragraph(
            "El an√°lisis de errores eval√∫a la capacidad del sistema para manejar "
            "situaciones excepcionales y retornar c√≥digos de estado HTTP apropiados.",
            self.custom_styles['body']
        )
        elements.append(desc)
        elements.append(Spacer(1, 0.2*inch))
        
        # Datos de errores
        errors = test_data.get("errors", {})
        
        if errors:
            # Tabla de c√≥digos de error
            error_data = [["C√≥digo HTTP", "Descripci√≥n", "Ocurrencias", "Estado"]]
            
            error_descriptions = {
                "400": "Bad Request - Datos inv√°lidos",
                "404": "Not Found - Recurso no encontrado", 
                "415": "Unsupported Media Type",
                "500": "Internal Server Error"
            }
            
            for code, count in errors.items():
                description = error_descriptions.get(code, "Error desconocido")
                status = "‚úÖ MANEJADO" if count > 0 else "‚ûñ NO PROBADO"
                
                error_data.append([
                    code,
                    description,
                    str(count),
                    status
                ])
            
            error_table = Table(error_data, colWidths=[1*inch, 3*inch, 1.5*inch, 1.5*inch])
            error_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), self.colors['primary']),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 9),
                ('BACKGROUND', (0, 1), (-1, -1), self.colors['light_gray']),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            elements.append(error_table)
        
        return elements
    
    def _create_recommendations(self, test_data: Dict[str, Any]) -> List:
        """Crear secci√≥n de recomendaciones"""
        elements = []
        
        # T√≠tulo de secci√≥n
        title = Paragraph("Recomendaciones y Conclusiones", self.custom_styles['subtitle'])
        elements.append(title)
        
        # Analizar datos para generar recomendaciones
        summary = test_data.get("summary", {})
        performance = test_data.get("performance", {})
        
        recommendations = []
        
        # Recomendaciones basadas en tasa de √©xito
        success_rate = summary.get("success_rate", 0)
        if success_rate < 95:
            recommendations.append({
                "type": "Funcionalidad",
                "priority": "Alta",
                "text": f"Mejorar la tasa de √©xito actual ({success_rate:.1f}%) "
                       "investigando y corrigiendo las pruebas fallidas."
            })
        
        # Recomendaciones de rendimiento
        response_times = performance.get("response_times", {})
        thresholds = performance.get("thresholds", {})
        
        for endpoint, times in response_times.items():
            if times:
                avg_time = np.mean(times)
                threshold = thresholds.get(endpoint, 200)
                
                if avg_time > threshold:
                    recommendations.append({
                        "type": "Rendimiento",
                        "priority": "Media",
                        "text": f"Optimizar endpoint '{endpoint}' que excede el umbral "
                               f"({avg_time:.1f}ms > {threshold}ms)."
                    })
        
        # Recomendaciones generales
        recommendations.extend([
            {
                "type": "Cobertura",
                "priority": "Media",
                "text": "Expandir cobertura de pruebas incluyendo m√°s casos edge y escenarios de carga."
            },
            {
                "type": "Monitoreo",
                "priority": "Baja",
                "text": "Implementar monitoreo continuo en producci√≥n basado en estas m√©tricas."
            },
            {
                "type": "Documentaci√≥n",
                "priority": "Baja",
                "text": "Mantener documentaci√≥n actualizada de los endpoints basada en resultados de testing."
            }
        ])
        
        # Crear tabla de recomendaciones
        if recommendations:
            rec_data = [["√Årea", "Prioridad", "Recomendaci√≥n"]]
            
            for rec in recommendations:
                priority_colors = {
                    "Alta": "üî¥",
                    "Media": "üü°", 
                    "Baja": "üü¢"
                }
                
                priority_icon = priority_colors.get(rec["priority"], "üîµ")
                
                rec_data.append([
                    rec["type"],
                    f"{priority_icon} {rec['priority']}",
                    rec["text"]
                ])
            
            rec_table = Table(rec_data, colWidths=[1.5*inch, 1.5*inch, 4*inch])
            rec_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), self.colors['primary']),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (1, -1), 'CENTER'),
                ('ALIGN', (2, 0), (2, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 9),
                ('BACKGROUND', (0, 1), (-1, -1), self.colors['light_gray']),
                ('GRID', (0, 0), (-1, -1), 1, colors.black),
                ('VALIGN', (0, 0), (-1, -1), 'TOP')
            ]))
            
            elements.append(rec_table)
        
        elements.append(Spacer(1, 0.3*inch))
        
        # Conclusi√≥n final
        conclusion_text = f"""
        <b>Conclusi√≥n General:</b><br/>
        Las pruebas de integraci√≥n han validado exitosamente el funcionamiento del microservicio 
        de gesti√≥n de productos AgroWeb. Con una tasa de √©xito del {success_rate:.1f}%, el sistema 
        demuestra robustez en el manejo de operaciones CRUD, validaci√≥n de errores y rendimiento 
        dentro de par√°metros aceptables.
        <br/><br/>
        <b>Pr√≥ximos Pasos:</b><br/>
        ‚Ä¢ Implementar las recomendaciones de prioridad alta<br/>
        ‚Ä¢ Establecer pipeline de CI/CD con estas pruebas<br/>
        ‚Ä¢ Configurar monitoreo de m√©tricas en producci√≥n<br/>
        ‚Ä¢ Realizar pruebas de carga m√°s extensivas
        """
        
        conclusion = Paragraph(conclusion_text, self.custom_styles['body'])
        elements.append(conclusion)
        
        return elements

def generate_integration_report() -> str:
    """Funci√≥n principal para generar reporte de integraci√≥n"""
    generator = PDFReportGenerator()
    return generator.generate_integration_report()

if __name__ == "__main__":
    # Generar reporte standalone
    report_path = generate_integration_report()
    print(f"‚úÖ Reporte generado: {report_path}")
